"""
Sistema Avan√ßado de Rastreamento ESP32-CAM com IA
Integra YOLO v8, DeepSORT, Face Recognition e t√©cnicas modernas
Arquitetura profissional com separa√ß√£o de responsabilidades
"""

import cv2
import time
import threading
import tkinter as tk
from tkinter import messagebox, ttk, filedialog, simpledialog
from PIL import Image, ImageTk
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import os
import numpy as np
from queue import Queue, Empty
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any
import json
from pathlib import Path
import sqlite3
from datetime import datetime
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import seaborn as sns

# Configura√ß√£o avan√ßada de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tracking_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class SystemConfig:
    """Configura√ß√µes centralizadas do sistema"""
    # Conex√£o ESP32-CAM
    ESP32_STREAM_URL: str = "http://192.168.0.100:81/stream"
    esp32_url: str = "http://192.168.0.100:81/stream"
    backup_urls: List[str] = field(default_factory=lambda: [
        "http://192.168.1.100:81/stream",
        "http://192.168.0.101:81/stream"
    ])
    
    # Modelos AI
    yolo_model: str = "yolov8n.pt"
    face_recognition_model: str = "dlib"  # ou "mtcnn", "insightface"
    
    # Tracking parameters
    detection_threshold: float = 0.5
    tracking_max_age: int = 30
    tracking_max_iou: float = 0.7
    
    # Interface
    display_width: int = 800
    display_height: int = 600
    fps_limit: int = 30
    
    # Storage
    faces_path: str = "known_faces"
    output_path: str = "tracking_outputs"
    database_path: str = "tracking_data.db"
    
    # Performance
    frame_skip: int = 1  # Process every nth frame
    face_recognition_interval: int = 5  # Process faces every nth frame
    max_concurrent_faces: int = 10

class DatabaseManager:
    """Gerenciador de banco de dados para logs e estat√≠sticas"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Inicializa o banco de dados"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS tracking_sessions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    start_time TIMESTAMP,
                    end_time TIMESTAMP,
                    total_detections INTEGER,
                    unique_persons INTEGER,
                    avg_fps REAL
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS face_identifications (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id INTEGER,
                    timestamp TIMESTAMP,
                    person_name TEXT,
                    confidence REAL,
                    bbox_x INTEGER,
                    bbox_y INTEGER,
                    bbox_w INTEGER,
                    bbox_h INTEGER,
                    FOREIGN KEY (session_id) REFERENCES tracking_sessions (id)
                )
            ''')
    
    def start_session(self) -> int:
        """Inicia nova sess√£o de tracking"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                'INSERT INTO tracking_sessions (start_time) VALUES (?)',
                (datetime.now(),)
            )
            return cursor.lastrowid
    
    def end_session(self, session_id: int, stats: Dict):
        """Finaliza sess√£o de tracking"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                UPDATE tracking_sessions 
                SET end_time = ?, total_detections = ?, unique_persons = ?, avg_fps = ?
                WHERE id = ?
            ''', (datetime.now(), stats.get('total_detections', 0),
                  stats.get('unique_persons', 0), stats.get('avg_fps', 0), session_id))
    
    def log_face_identification(self, session_id: int, person_name: str, 
                              confidence: float, bbox: Tuple[int, int, int, int]):
        """Registra identifica√ß√£o facial"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO face_identifications 
                (session_id, timestamp, person_name, confidence, bbox_x, bbox_y, bbox_w, bbox_h)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (session_id, datetime.now(), person_name, confidence, *bbox))

class AIModelManager:
    """Gerenciador centralizado dos modelos de IA"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        self.yolo_model = None
        self.tracker = None
        self.face_recognition_enabled = False
        self.face_encodings = {}
        self.face_names = []
        
        self._init_models()
    
    def _init_models(self):
        """Inicializa todos os modelos"""
        try:
            # YOLO v8
            logger.info("Carregando modelo YOLO...")
            self.yolo_model = YOLO(self.config.yolo_model)
            logger.info("‚úÖ YOLO carregado com sucesso")
            
            # DeepSORT Tracker
            logger.info("Inicializando tracker DeepSORT...")
            self.tracker = DeepSort(
                max_age=self.config.tracking_max_age,
                max_iou_distance=self.config.tracking_max_iou,
                n_init=3
            )
            logger.info("‚úÖ DeepSORT inicializado")
            
            # Face Recognition
            self._init_face_recognition()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar modelos: {e}")
            raise
    
    def _init_face_recognition(self):
        """Inicializa sistema de reconhecimento facial"""
        try:
            import face_recognition
            import dlib
            
            self.face_recognition = face_recognition
            self.face_recognition_enabled = True
            self._load_known_faces()
            logger.info("‚úÖ Reconhecimento facial habilitado")
            
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Reconhecimento facial desabilitado: {e}")
            self.face_recognition_enabled = False
    
    def _load_known_faces(self):
        """Carrega faces conhecidas otimizado"""
        faces_path = Path(self.config.faces_path)
        faces_path.mkdir(exist_ok=True)
        
        supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')
        face_files = [f for f in faces_path.iterdir() 
                     if f.suffix.lower() in supported_formats]
        
        logger.info(f"Carregando {len(face_files)} imagens de faces...")
        
        for face_file in face_files:
            try:
                image = self.face_recognition.load_image_file(str(face_file))
                encodings = self.face_recognition.face_encodings(image, model="large")
                
                if encodings:
                    name = face_file.stem
                    self.face_encodings[name] = encodings[0]
                    self.face_names.append(name)
                    logger.info(f"‚úÖ Face carregada: {name}")
                else:
                    logger.warning(f"‚ö†Ô∏è Nenhuma face em: {face_file.name}")
                    
            except Exception as e:
                logger.error(f"‚ùå Erro ao carregar {face_file.name}: {e}")
        
        logger.info(f"Total de faces conhecidas: {len(self.face_names)}")
    
    def detect_objects(self, frame: np.ndarray) -> List[Dict]:
        """Detecta objetos usando YOLO"""
        results = self.yolo_model(frame, verbose=False, conf=self.config.detection_threshold)
        
        detections = []
        if results and len(results) > 0:
            for result in results[0].boxes.data.tolist():
                x1, y1, x2, y2, score, cls = result
                if int(cls) == 0:  # Person class
                    bbox = [x1, y1, x2 - x1, y2 - y1]  # Convert to [x, y, w, h]
                    detections.append({
                        'bbox': bbox,
                        'confidence': score,
                        'class': 'person',
                        'class_id': int(cls)
                    })
        
        return detections
    
    def update_tracks(self, detections: List[Dict], frame: np.ndarray):
        """Atualiza tracking com DeepSORT"""
        detection_list = [(det['bbox'], det['confidence'], det['class']) 
                         for det in detections]
        
        return self.tracker.update_tracks(detection_list, frame=frame)
    
    def identify_faces(self, frame: np.ndarray, face_locations: List) -> List[Dict]:
        """Identifica faces no frame"""
        if not self.face_recognition_enabled or not self.face_encodings:
            return []
        
        try:
            # Limitar n√∫mero de faces processadas
            face_locations = face_locations[:self.config.max_concurrent_faces]
            
            face_encodings = self.face_recognition.face_encodings(
                frame, face_locations, model="large"
            )
            
            identifications = []
            known_encodings = list(self.face_encodings.values())
            known_names = list(self.face_encodings.keys())
            
            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
                matches = self.face_recognition.compare_faces(
                    known_encodings, face_encoding, tolerance=0.4
                )
                
                name = "Desconhecido"
                confidence = 0.0
                
                face_distances = self.face_recognition.face_distance(known_encodings, face_encoding)
                best_match_index = np.argmin(face_distances)
                
                if matches[best_match_index]:
                    name = known_names[best_match_index]
                    confidence = 1 - face_distances[best_match_index]
                
                identifications.append({
                    'name': name,
                    'confidence': confidence,
                    'location': (top, right, bottom, left),
                    'bbox': (left, top, right - left, bottom - top)
                })
            
            return identifications
            
        except Exception as e:
            logger.error(f"Erro na identifica√ß√£o facial: {e}")
            return []

class VideoProcessor:
    """Processador de v√≠deo otimizado"""
    
    def __init__(self, config: SystemConfig, ai_manager: AIModelManager, db_manager: DatabaseManager):
        self.config = config
        self.ai_manager = ai_manager
        self.db_manager = db_manager
        self.frame_count = 0
        self.session_id = None
        
        # M√©tricas
        self.fps_history = []
        self.detection_history = []
        self.face_history = []
        
        # Estado
        self.active_tracks = {}
        self.total_detections = 0
        self.unique_persons = set()
    
    def start_session(self):
        """Inicia nova sess√£o de processamento"""
        self.session_id = self.db_manager.start_session()
        self.frame_count = 0
        self.total_detections = 0
        self.unique_persons.clear()
        logger.info(f"Nova sess√£o iniciada: {self.session_id}")
    
    def end_session(self):
        """Finaliza sess√£o atual"""
        if self.session_id:
            stats = {
                'total_detections': self.total_detections,
                'unique_persons': len(self.unique_persons),
                'avg_fps': np.mean(self.fps_history) if self.fps_history else 0
            }
            self.db_manager.end_session(self.session_id, stats)
            logger.info(f"Sess√£o finalizada: {self.session_id}")
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:
        """Processa um frame completo"""
        start_time = time.time()
        self.frame_count += 1
        
        # Skip frames para otimiza√ß√£o
        if self.frame_count % self.config.frame_skip != 0:
            return frame, self._get_current_stats()
        
        try:
            # 1. Detec√ß√£o YOLO
            detections = self.ai_manager.detect_objects(frame)
            self.total_detections += len(detections)
            
            # 2. Tracking DeepSORT
            tracks = self.ai_manager.update_tracks(detections, frame)
            
            # 3. Processar tracks ativos
            active_tracks = []
            for track in tracks:
                if not track.is_confirmed():
                    continue
                
                track_id = track.track_id
                self.unique_persons.add(track_id)
                x1, y1, x2, y2 = map(int, track.to_ltrb())
                
                active_tracks.append({
                    'id': track_id,
                    'bbox': (x1, y1, x2, y2),
                    'confidence': getattr(track, 'confidence', 0.0)
                })
            
            # 4. Reconhecimento facial (intervalos)
            face_identifications = []
            if (self.ai_manager.face_recognition_enabled and 
                self.frame_count % self.config.face_recognition_interval == 0):
                
                # Redimensionar para acelerar processamento
                small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
                face_locations = self.ai_manager.face_recognition.face_locations(
                    small_frame, model="hog"
                )
                
                # Escalar coordenadas de volta
                face_locations = [(top*2, right*2, bottom*2, left*2) 
                                for (top, right, bottom, left) in face_locations]
                
                face_identifications = self.ai_manager.identify_faces(frame, face_locations)
                
                # Log identifica√ß√µes no banco
                for identification in face_identifications:
                    if identification['confidence'] > 0.6:  # Threshold de confian√ßa
                        self.db_manager.log_face_identification(
                            self.session_id,
                            identification['name'],
                            identification['confidence'],
                            identification['bbox']
                        )
            
            # 5. Anotar frame
            annotated_frame = self._annotate_frame(frame, active_tracks, face_identifications)
            
            # 6. Atualizar m√©tricas
            processing_time = time.time() - start_time
            fps = 1.0 / processing_time if processing_time > 0 else 0
            self.fps_history.append(fps)
            self.detection_history.append(len(active_tracks))
            self.face_history.append(len(face_identifications))
            
            # Manter hist√≥rico limitado
            max_history = 300  # 10 segundos a 30fps
            self.fps_history = self.fps_history[-max_history:]
            self.detection_history = self.detection_history[-max_history:]
            self.face_history = self.face_history[-max_history:]
            
            return annotated_frame, self._get_current_stats()
            
        except Exception as e:
            logger.error(f"Erro no processamento do frame: {e}")
            return frame, self._get_current_stats()
    
    def _annotate_frame(self, frame: np.ndarray, tracks: List[Dict], faces: List[Dict]) -> np.ndarray:
        """Anota frame com informa√ß√µes visuais"""
        annotated = frame.copy()
        
        # Desenhar tracks de pessoas
        for track in tracks:
            x1, y1, x2, y2 = track['bbox']
            
            # Caixa de tracking
            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ID e confian√ßa
            label = f"ID: {track['id']}"
            cv2.putText(annotated, label, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # Desenhar identifica√ß√µes faciais
        for face in faces:
            top, right, bottom, left = face['location']
            name = face['name']
            confidence = face['confidence']
            
            # Cor baseada na confian√ßa
            color = (0, 255, 0) if confidence > 0.7 else (0, 165, 255)
            
            # Caixa facial
            cv2.rectangle(annotated, (left, top), (right, bottom), color, 2)
            
            # Nome e confian√ßa
            text = f"{name} ({confidence:.2f})"
            cv2.putText(annotated, text, (left, top - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Informa√ß√µes do sistema
        self._draw_info_panel(annotated)
        
        return annotated
    
    def _draw_info_panel(self, frame: np.ndarray):
        """Desenha painel de informa√ß√µes"""
        h, w = frame.shape[:2]
        
        # Painel semi-transparente
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (350, 140), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # Informa√ß√µes
        stats = self._get_current_stats()
        info_lines = [
            f"FPS: {stats['current_fps']:.1f} (avg: {stats['avg_fps']:.1f})",
            f"Frame: {self.frame_count}",
            f"Pessoas Ativas: {stats['active_persons']}",
            f"Pessoas √önicas: {stats['unique_persons']}",
            f"Faces Identificadas: {stats['faces_detected']}",
            f"Total Detec√ß√µes: {self.total_detections}"
        ]
        
        for i, line in enumerate(info_lines):
            y = 30 + (i * 18)
            cv2.putText(frame, line, (15, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def _get_current_stats(self) -> Dict:
        """Retorna estat√≠sticas atuais"""
        return {
            'current_fps': self.fps_history[-1] if self.fps_history else 0,
            'avg_fps': np.mean(self.fps_history) if self.fps_history else 0,
            'active_persons': self.detection_history[-1] if self.detection_history else 0,
            'unique_persons': len(self.unique_persons),
            'faces_detected': self.face_history[-1] if self.face_history else 0,
            'total_detections': self.total_detections,
            'frame_count': self.frame_count
        }

class AdvancedTrackingGUI:
    """Interface gr√°fica avan√ßada do sistema"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        self.db_manager = DatabaseManager(config.database_path)
        self.ai_manager = AIModelManager(config)
        self.video_processor = VideoProcessor(config, self.ai_manager, self.db_manager)
        
        # Estado da aplica√ß√£o
        self.is_running = False
        self.is_paused = False
        self.frame_queue = Queue(maxsize=3)
        self.current_frame = None
        self.video_thread = None
        
        # Conex√£o ESP32
        self.current_url_index = 0
        self.all_urls = [config.ESP32_STREAM_URL] + config.backup_urls
        
        # Inicializar interface
        self._init_gui()
        
        # Configurar paths
        Path(config.faces_path).mkdir(exist_ok=True)
        Path(config.output_path).mkdir(exist_ok=True)
    
    def _init_gui(self):
        """Inicializa interface gr√°fica moderna"""
        self.root = tk.Tk()
        self.root.title("üõ∞Ô∏è ESP32-CAM AI Tracking System Pro")
        self.root.geometry("1200x900")
        self.root.configure(bg='#2b2b2b')
        
        # Estilo moderno
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('Title.TLabel', font=('Arial', 14, 'bold'))
        
        self._create_main_layout()
        self._create_menu()
        
    def _create_main_layout(self):
        """Cria layout principal da interface"""
        # Frame principal dividido
        main_paned = tk.PanedWindow(self.root, orient=tk.HORIZONTAL, bg='#2b2b2b')
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Painel esquerdo - V√≠deo
        left_frame = tk.Frame(main_paned, bg='#2b2b2b')
        main_paned.add(left_frame, width=800)
        
        # Painel direito - Controles e estat√≠sticas
        right_frame = tk.Frame(main_paned, bg='#3b3b3b', width=400)
        main_paned.add(right_frame)
        
        self._create_video_panel(left_frame)
        self._create_control_panel(right_frame)
        self._create_stats_panel(right_frame)
    
    def _create_video_panel(self, parent):
        """Cria painel de v√≠deo"""
        video_frame = tk.LabelFrame(parent, text="üìπ V√≠deo Stream", 
                                   font=('Arial', 12, 'bold'), bg='#2b2b2b', fg='white')
        video_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Canvas para v√≠deo com scroll se necess√°rio
        self.video_canvas = tk.Canvas(
            video_frame,
            width=self.config.display_width,
            height=self.config.display_height,
            bg='black'
        )
        self.video_canvas.pack(pady=10)
        
        # Label para o v√≠deo
        self.video_label = tk.Label(
            self.video_canvas,
            text="Pressione 'Iniciar' para come√ßar",
            font=('Arial', 14),
            bg='black',
            fg='white'
        )
        self.video_label.pack(expand=True)
    
    def _create_control_panel(self, parent):
        """Cria painel de controles"""
        control_frame = tk.LabelFrame(parent, text="üéÆ Controles", 
                                     font=('Arial', 12, 'bold'), bg='#3b3b3b', fg='white')
        control_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # Bot√µes principais
        btn_frame = tk.Frame(control_frame, bg='#3b3b3b')
        btn_frame.pack(pady=10)
        
        self.btn_start = tk.Button(
            btn_frame, text="‚ñ∂Ô∏è Iniciar", width=12, height=2,
            command=self.start_tracking, 
            bg='#4CAF50', fg='white', font=('Arial', 10, 'bold')
        )
        self.btn_start.grid(row=0, column=0, padx=5, pady=2)
        
        self.btn_pause = tk.Button(
            btn_frame, text="‚è∏Ô∏è Pausar", width=12, height=2,
            command=self.pause_tracking, state='disabled',
            bg='#FF9800', fg='white', font=('Arial', 10, 'bold')
        )
        self.btn_pause.grid(row=0, column=1, padx=5, pady=2)
        
        self.btn_stop = tk.Button(
            btn_frame, text="‚èπÔ∏è Parar", width=12, height=2,
            command=self.stop_tracking, state='disabled',
            bg='#f44336', fg='white', font=('Arial', 10, 'bold')
        )
        self.btn_stop.grid(row=1, column=0, padx=5, pady=2)
        
        self.btn_save = tk.Button(
            btn_frame, text="üíæ Salvar", width=12, height=2,
            command=self.save_frame,
            bg='#2196F3', fg='white', font=('Arial', 10, 'bold')
        )
        self.btn_save.grid(row=1, column=1, padx=5, pady=2)
        
        # Configura√ß√µes
        config_frame = tk.LabelFrame(control_frame, text="‚öôÔ∏è Configura√ß√µes", 
                                    bg='#3b3b3b', fg='white')
        config_frame.pack(fill=tk.X, padx=10, pady=10)
        
        # URL ESP32
        tk.Label(config_frame, text="ESP32-CAM URL:", bg='#3b3b3b', fg='white').pack(anchor='w')
        self.url_var = tk.StringVar(value=self.config.ESP32_STREAM_URL)
        url_entry = tk.Entry(config_frame, textvariable=self.url_var, width=40)
        url_entry.pack(fill='x', pady=2)
        
        # Threshold de detec√ß√£o
        tk.Label(config_frame, text="Threshold Detec√ß√£o:", bg='#3b3b3b', fg='white').pack(anchor='w')
        self.threshold_var = tk.DoubleVar(value=self.config.detection_threshold)
        threshold_scale = tk.Scale(
            config_frame, from_=0.1, to=0.9, resolution=0.1,
            orient='horizontal', variable=self.threshold_var,
            bg='#3b3b3b', fg='white', highlightbackground='#3b3b3b'
        )
        threshold_scale.pack(fill='x', pady=2)
        
        # Bot√µes de utilit√°rios
        util_frame = tk.Frame(control_frame, bg='#3b3b3b')
        util_frame.pack(fill='x', pady=10)
        
        tk.Button(
            util_frame, text="üìä Estat√≠sticas", width=15,
            command=self.show_statistics,
            bg='#9C27B0', fg='white', font=('Arial', 9, 'bold')
        ).pack(side='left', padx=5)
        
        tk.Button(
            util_frame, text="üë• Gerenciar Faces", width=15,
            command=self.manage_faces,
            bg='#607D8B', fg='white', font=('Arial', 9, 'bold')
        ).pack(side='right', padx=5)
    
    def _create_stats_panel(self, parent):
        """Cria painel de estat√≠sticas em tempo real"""
        stats_frame = tk.LabelFrame(parent, text="üìà Estat√≠sticas em Tempo Real", 
                                   font=('Arial', 12, 'bold'), bg='#3b3b3b', fg='white')
        stats_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Estat√≠sticas textuais
        self.stats_text = tk.Text(
            stats_frame, height=8, width=35,
            bg='#2b2b2b', fg='#00ff00', font=('Courier', 10)
        )
        self.stats_text.pack(fill='x', padx=10, pady=10)
        
        # Gr√°fico de FPS (placeholder)
        self.stats_canvas = tk.Canvas(stats_frame, height=200, bg='#2b2b2b')
        self.stats_canvas.pack(fill='x', padx=10, pady=10)
        
        # Status bar
        self.status_var = tk.StringVar()
        self.status_var.set("Sistema pronto")
        status_bar = tk.Label(
            self.root, textvariable=self.status_var,
            relief='sunken', anchor='w', bg='#2b2b2b', fg='white'
        )
        status_bar.pack(side='bottom', fill='x')
    
    def _create_menu(self):
        """Cria menu da aplica√ß√£o"""
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # Menu Arquivo
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Arquivo", menu=file_menu)
        file_menu.add_command(label="Carregar Configura√ß√£o", command=self.load_config)
        file_menu.add_command(label="Salvar Configura√ß√£o", command=self.save_config)
        file_menu.add_separator()
        file_menu.add_command(label="Exportar Dados", command=self.export_data)
        file_menu.add_separator()
        file_menu.add_command(label="Sair", command=self.on_closing)
        
        # Menu Ferramentas
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Ferramentas", menu=tools_menu)
        tools_menu.add_command(label="Calibrar C√¢mera", command=self.calibrate_camera)
        tools_menu.add_command(label="Testar Conex√£o", command=self.test_connection)
        tools_menu.add_command(label="Limpar Banco de Dados", command=self.clear_database)
        
        # Menu Ajuda
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Ajuda", menu=help_menu)
        help_menu.add_command(label="Sobre", command=self.show_about)
        help_menu.add_command(label="Manual", command=self.show_manual)
    
    def start_tracking(self):
        """Inicia o sistema de tracking"""
        if self.is_running:
            return
        
        try:
            # Atualizar configura√ß√µes
            self.config.ESP32_STREAM_URL = self.url_var.get()
            self.config.esp32_url = self.url_var.get()
            self.config.detection_threshold = self.threshold_var.get()
            self.ai_manager.config = self.config
            
            self.is_running = True
            self.is_paused = False
            
            # Iniciar sess√£o de processamento
            self.video_processor.start_session()
            
            # Iniciar thread de captura
            self.video_thread = threading.Thread(target=self._video_capture_thread, daemon=True)
            self.video_thread.start()
            
            # Iniciar atualiza√ß√£o da interface
            self._update_display()
            
            # Atualizar bot√µes
            self._update_button_states()
            
            self.status_var.set("Sistema iniciado - Processando...")
            logger.info("üöÄ Sistema de tracking iniciado")
            
        except Exception as e:
            self.status_var.set(f"Erro ao iniciar: {str(e)}")
            messagebox.showerror("Erro", f"Falha ao iniciar o sistema:\n{e}")
            logger.error(f"Erro ao iniciar tracking: {e}")
    
    def pause_tracking(self):
        """Pausa/resume o tracking"""
        if not self.is_running:
            return
        
        self.is_paused = not self.is_paused
        
        status_text = "Sistema pausado" if self.is_paused else "Sistema ativo"
        self.status_var.set(status_text)
        
        button_text = "‚ñ∂Ô∏è Continuar" if self.is_paused else "‚è∏Ô∏è Pausar"
        self.btn_pause.config(text=button_text)
        
        logger.info(f"Sistema {'pausado' if self.is_paused else 'retomado'}")
    
    def stop_tracking(self):
        """Para o sistema de tracking"""
        if not self.is_running:
            return
        
        self.is_running = False
        self.is_paused = False
        
        # Finalizar sess√£o
        self.video_processor.end_session()
        
        # Atualizar interface
        self._update_button_states()
        self.status_var.set("Sistema parado")
        
        # Limpar display
        self.video_label.config(text="Pressione 'Iniciar' para come√ßar")
        
        logger.info("üõë Sistema de tracking parado")
    
    def _video_capture_thread(self):
        """Thread de captura de v√≠deo otimizada"""
        cap = None
        retry_count = 0
        max_retries = 3
        
        while self.is_running and retry_count < max_retries:
            try:
                # Tentar conectar com URLs alternativas
                current_url = self.all_urls[self.current_url_index % len(self.all_urls)]
                logger.info(f"Tentando conectar: {current_url}")
                
                cap = cv2.VideoCapture(current_url)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduzir buffer
                cap.set(cv2.CAP_PROP_FPS, self.config.fps_limit)
                
                if not cap.isOpened():
                    raise ConnectionError(f"Falha ao conectar com {current_url}")
                
                logger.info(f"‚úÖ Conectado com sucesso: {current_url}")
                retry_count = 0  # Reset contador em caso de sucesso
                
                # Loop principal de captura
                while self.is_running:
                    if self.is_paused:
                        time.sleep(0.1)
                        continue
                    
                    ret, frame = cap.read()
                    if not ret:
                        logger.warning("Falha na captura do frame")
                        break
                    
                    # Processar frame
                    processed_frame, stats = self.video_processor.process_frame(frame)
                    
                    # Enviar para interface (n√£o-bloqueante)
                    if not self.frame_queue.full():
                        try:
                            self.frame_queue.put_nowait((processed_frame, stats))
                        except:
                            pass  # Queue cheia, ignorar frame
                
            except Exception as e:
                retry_count += 1
                logger.error(f"Erro na captura (tentativa {retry_count}): {e}")
                
                if retry_count < max_retries:
                    # Tentar pr√≥xima URL
                    self.current_url_index += 1
                    time.sleep(2)
                else:
                    # Mostrar erro na interface
                    self.root.after(0, lambda: messagebox.showerror(
                        "Erro de Conex√£o", 
                        f"N√£o foi poss√≠vel conectar ap√≥s {max_retries} tentativas.\n"
                        f"Verifique as URLs: {self.all_urls}"
                    ))
                    break
            
            finally:
                if cap:
                    cap.release()
        
        logger.info("Thread de captura finalizada")
    
    def _update_display(self):
        """Atualiza display da interface"""
        try:
            if not self.frame_queue.empty():
                frame, stats = self.frame_queue.get_nowait()
                
                # Redimensionar frame para o display
                display_frame = self._resize_frame_for_display(frame)
                
                # Converter para formato Tkinter
                rgb_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(rgb_frame)
                photo = ImageTk.PhotoImage(pil_image)
                
                # Atualizar label
                self.video_label.config(image=photo, text="")
                self.video_label.image = photo  # Manter refer√™ncia
                
                # Salvar frame atual
                self.current_frame = frame
                
                # Atualizar estat√≠sticas
                self._update_stats_display(stats)
        
        except Empty:
            pass
        except Exception as e:
            logger.error(f"Erro na atualiza√ß√£o do display: {e}")
        
        # Agendar pr√≥xima atualiza√ß√£o
        if self.is_running:
            self.root.after(33, self._update_display)  # ~30 FPS
    
    def _resize_frame_for_display(self, frame: np.ndarray) -> np.ndarray:
        """Redimensiona frame mantendo propor√ß√£o"""
        h, w = frame.shape[:2]
        
        # Calcular nova dimens√£o mantendo propor√ß√£o
        aspect_ratio = w / h
        if aspect_ratio > self.config.display_width / self.config.display_height:
            new_w = self.config.display_width
            new_h = int(new_w / aspect_ratio)
        else:
            new_h = self.config.display_height
            new_w = int(new_h * aspect_ratio)
        
        return cv2.resize(frame, (new_w, new_h))
    
    def _update_stats_display(self, stats: Dict):
        """Atualiza display de estat√≠sticas"""
        self.stats_text.delete(1.0, tk.END)
        
        stats_text = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë      ESTAT√çSTICAS        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë FPS Atual: {stats['current_fps']:>6.1f}     ‚ïë
‚ïë FPS M√©dio: {stats['avg_fps']:>6.1f}     ‚ïë
‚ïë Frame: {stats['frame_count']:>10d}     ‚ïë
‚ïë Pessoas Ativas: {stats['active_persons']:>4d}   ‚ïë
‚ïë Pessoas √önicas: {stats['unique_persons']:>4d}   ‚ïë
‚ïë Faces Detectadas: {stats['faces_detected']:>3d}   ‚ïë
‚ïë Total Detec√ß√µes: {stats['total_detections']:>5d}  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """
        
        self.stats_text.insert(1.0, stats_text.strip())
        
        # Atualizar status bar
        status = f"FPS: {stats['current_fps']:.1f} | Pessoas: {stats['active_persons']} | Faces: {stats['faces_detected']}"
        self.status_var.set(status)
    
    def _update_button_states(self):
        """Atualiza estado dos bot√µes baseado no status"""
        if self.is_running:
            self.btn_start.config(state='disabled')
            self.btn_pause.config(state='normal')
            self.btn_stop.config(state='normal')
        else:
            self.btn_start.config(state='normal')
            self.btn_pause.config(state='disabled')
            self.btn_stop.config(state='disabled')
    
    def save_frame(self):
        """Salva o frame atual"""
        if self.current_frame is None:
            messagebox.showwarning("Aviso", "Nenhum frame dispon√≠vel para salvar")
            return
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.config.output_path}/frame_{timestamp}.jpg"
            
            cv2.imwrite(filename, self.current_frame)
            messagebox.showinfo("Sucesso", f"Frame salvo como:\n{filename}")
            logger.info(f"üíæ Frame salvo: {filename}")
            
        except Exception as e:
            messagebox.showerror("Erro", f"Erro ao salvar frame:\n{e}")
            logger.error(f"Erro ao salvar frame: {e}")
    
    def show_statistics(self):
        """Mostra janela de estat√≠sticas avan√ßadas"""
        try:
            stats_window = tk.Toplevel(self.root)
            stats_window.title("üìä Estat√≠sticas Avan√ßadas")
            stats_window.geometry("800x600")
            stats_window.configure(bg='#2b2b2b')
            
            # Criar gr√°ficos com matplotlib
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8), facecolor='#2b2b2b')
            
            # FPS ao longo do tempo
            fps_data = self.video_processor.fps_history[-100:]
            ax1.plot(fps_data, color='#00ff00', linewidth=2)
            ax1.set_title('FPS em Tempo Real', color='white')
            ax1.set_ylabel('FPS', color='white')
            ax1.set_facecolor('#3b3b3b')
            ax1.tick_params(colors='white')
            
            # Detec√ß√µes ao longo do tempo
            detection_data = self.video_processor.detection_history[-100:]
            ax2.plot(detection_data, color='#ff6600', linewidth=2)
            ax2.set_title('Pessoas Detectadas', color='white')
            ax2.set_ylabel('Pessoas', color='white')
            ax2.set_facecolor('#3b3b3b')
            ax2.tick_params(colors='white')
            
            # Histograma de FPS
            ax3.hist(fps_data, bins=20, color='#00ff00', alpha=0.7, edgecolor='white')
            ax3.set_title('Distribui√ß√£o de FPS', color='white')
            ax3.set_xlabel('FPS', color='white')
            ax3.set_ylabel('Frequ√™ncia', color='white')
            ax3.set_facecolor('#3b3b3b')
            ax3.tick_params(colors='white')
            
            # Faces detectadas
            face_data = self.video_processor.face_history[-100:]
            ax4.plot(face_data, color='#ff00ff', linewidth=2)
            ax4.set_title('Faces Identificadas', color='white')
            ax4.set_ylabel('Faces', color='white')
            ax4.set_facecolor('#3b3b3b')
            ax4.tick_params(colors='white')
            
            plt.tight_layout()
            
            # Incorporar gr√°fico no Tkinter
            canvas = FigureCanvasTkAgg(fig, stats_window)
            canvas.draw()
            canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            
        except Exception as e:
            messagebox.showerror("Erro", f"Erro ao gerar estat√≠sticas:\n{e}")
            logger.error(f"Erro nas estat√≠sticas: {e}")
    
    def manage_faces(self):
        """Abre gerenciador de faces conhecidas"""
        faces_window = tk.Toplevel(self.root)
        faces_window.title("üë• Gerenciar Faces Conhecidas")
        faces_window.geometry("600x500")
        faces_window.configure(bg='#2b2b2b')
        
        # Lista de faces
        list_frame = tk.LabelFrame(faces_window, text="Faces Conhecidas", 
                                  bg='#2b2b2b', fg='white', font=('Arial', 12, 'bold'))
        list_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Listbox com scrollbar
        list_container = tk.Frame(list_frame, bg='#2b2b2b')
        list_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        scrollbar = tk.Scrollbar(list_container)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        self.faces_listbox = tk.Listbox(
            list_container, yscrollcommand=scrollbar.set,
            bg='#3b3b3b', fg='white', font=('Arial', 11)
        )
        self.faces_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.config(command=self.faces_listbox.yview)
        
        # Carregar lista de faces
        self._refresh_faces_list()
        
        # Bot√µes
        btn_frame = tk.Frame(faces_window, bg='#2b2b2b')
        btn_frame.pack(fill=tk.X, padx=10, pady=10)
        
        tk.Button(
            btn_frame, text="‚ûï Adicionar Face", width=15,
            command=self.add_face, bg='#4CAF50', fg='white', font=('Arial', 10, 'bold')
        ).pack(side='left', padx=5)
        
        tk.Button(
            btn_frame, text="üóëÔ∏è Remover Face", width=15,
            command=self.remove_face, bg='#f44336', fg='white', font=('Arial', 10, 'bold')
        ).pack(side='left', padx=5)
        
        tk.Button(
            btn_frame, text="üîÑ Recarregar", width=15,
            command=self.reload_faces, bg='#2196F3', fg='white', font=('Arial', 10, 'bold')
        ).pack(side='right', padx=5)
    
    def _refresh_faces_list(self):
        """Atualiza lista de faces na interface"""
        self.faces_listbox.delete(0, tk.END)
        for name in self.ai_manager.face_names:
            self.faces_listbox.insert(tk.END, name)
    
    def add_face(self):
        """Adiciona nova face conhecida"""
        file_path = filedialog.askopenfilename(
            title="Selecionar Imagem da Face",
            filetypes=[("Imagens", "*.jpg *.jpeg *.png *.bmp")]
        )
        
        if not file_path:
            return
        
        # Solicitar nome
        name = simpledialog.askstring("Nome da Pessoa", "Digite o nome da pessoa:")
        if not name:
            return
        
        try:
            # Copiar arquivo para pasta de faces
            src_path = Path(file_path)
            dst_path = Path(self.config.faces_path) / f"{name}{src_path.suffix}"
            
            import shutil
            shutil.copy2(file_path, dst_path)
            
            messagebox.showinfo("Sucesso", f"Face adicionada: {name}")
            logger.info(f"Nova face adicionada: {name}")
            
        except Exception as e:
            messagebox.showerror("Erro", f"Erro ao adicionar face:\n{e}")
            logger.error(f"Erro ao adicionar face: {e}")
    
    def remove_face(self):
        """Remove face selecionada"""
        selection = self.faces_listbox.curselection()
        if not selection:
            messagebox.showwarning("Aviso", "Selecione uma face para remover")
            return
        
        name = self.faces_listbox.get(selection[0])
        
        if messagebox.askyesno("Confirmar", f"Remover a face '{name}'?"):
            try:
                # Encontrar e remover arquivo
                faces_path = Path(self.config.faces_path)
                for file_path in faces_path.glob(f"{name}.*"):
                    file_path.unlink()
                    break
                
                messagebox.showinfo("Sucesso", f"Face removida: {name}")
                logger.info(f"Face removida: {name}")
                
            except Exception as e:
                messagebox.showerror("Erro", f"Erro ao remover face:\n{e}")
                logger.error(f"Erro ao remover face: {e}")
    
    def reload_faces(self):
        """Recarrega faces conhecidas"""
        try:
            self.ai_manager._load_known_faces()
            self._refresh_faces_list()
            messagebox.showinfo("Sucesso", "Faces recarregadas com sucesso!")
            logger.info("Faces recarregadas")
        except Exception as e:
            messagebox.showerror("Erro", f"Erro ao recarregar faces:\n{e}")
    
    def test_connection(self):
        """Testa conex√£o com ESP32-CAM"""
        test_window = tk.Toplevel(self.root)
        test_window.title("üîó Teste de Conex√£o")
        test_window.geometry("400x300")
        test_window.configure(bg='#2b2b2b')
        
        result_text = tk.Text(
            test_window, height=15, width=50,
            bg='#3b3b3b', fg='white', font=('Courier', 10)
        )
        result_text.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)
        
        def run_test():
            result_text.insert(tk.END, "Iniciando teste de conex√£o...\n\n")
            
            for i, url in enumerate(self.all_urls):
                result_text.insert(tk.END, f"Testando URL {i+1}: {url}\n")
                result_text.update()
                
                try:
                    cap = cv2.VideoCapture(url)
                    if cap.isOpened():
                        ret, frame = cap.read()
                        if ret:
                            result_text.insert(tk.END, "‚úÖ Conex√£o OK - Frame capturado\n\n")
                        else:
                            result_text.insert(tk.END, "‚ö†Ô∏è Conex√£o OK - Erro na captura\n\n")
                    else:
                        result_text.insert(tk.END, "‚ùå Falha na conex√£o\n\n")
                    cap.release()
                    
                except Exception as e:
                    result_text.insert(tk.END, f"‚ùå Erro: {e}\n\n")
                
                result_text.see(tk.END)
                result_text.update()
        
        threading.Thread(target=run_test, daemon=True).start()
    
    def load_config(self):
        """Carrega configura√ß√£o de arquivo JSON"""
        file_path = filedialog.askopenfilename(
            title="Carregar Configura√ß√£o",
            filetypes=[("JSON files", "*.json")]
        )
        
        if file_path:
            try:
                with open(file_path, 'r') as f:
                    config_data = json.load(f)
                
                # Atualizar configura√ß√µes
                for key, value in config_data.items():
                    if hasattr(self.config, key):
                        setattr(self.config, key, value)
                
                # Atualizar interface
                self.url_var.set(self.config.ESP32_STREAM_URL)
                self.threshold_var.set(self.config.detection_threshold)
                
                messagebox.showinfo("Sucesso", "Configura√ß√£o carregada!")
                
            except Exception as e:
                messagebox.showerror("Erro", f"Erro ao carregar configura√ß√£o:\n{e}")
    
    def save_config(self):
        """Salva configura√ß√£o atual em arquivo JSON"""
        file_path = filedialog.asksaveasfilename(
            title="Salvar Configura√ß√£o",
            defaultextension=".json",
            filetypes=[("JSON files", "*.json")]
        )
        
        if file_path:
            try:
                config_data = {
                    'ESP32_STREAM_URL': self.config.ESP32_STREAM_URL,
                    'esp32_url': self.config.esp32_url,
                    'detection_threshold': self.config.detection_threshold,
                    'tracking_max_age': self.config.tracking_max_age,
                    'display_width': self.config.display_width,
                    'display_height': self.config.display_height,
                    'fps_limit': self.config.fps_limit
                }
                
                with open(file_path, 'w') as f:
                    json.dump(config_data, f, indent=2)
                
                messagebox.showinfo("Sucesso", "Configura√ß√£o salva!")
                
            except Exception as e:
                messagebox.showerror("Erro", f"Erro ao salvar configura√ß√£o:\n{e}")
    
    def export_data(self):
        """Exporta dados do banco para CSV"""
        file_path = filedialog.asksaveasfilename(
            title="Exportar Dados",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv")]
        )
        
        if file_path:
            try:
                import pandas as pd
                
                # Conectar ao banco
                conn = sqlite3.connect(self.config.database_path)
                
                # Exportar sess√µes
                sessions_df = pd.read_sql_query(
                    "SELECT * FROM tracking_sessions", conn
                )
                
                # Exportar identifica√ß√µes faciais
                faces_df = pd.read_sql_query(
                    "SELECT * FROM face_identifications", conn
                )
                
                conn.close()
                
                # Salvar CSVs
                base_path = Path(file_path).stem
                sessions_df.to_csv(f"{base_path}_sessions.csv", index=False)
                faces_df.to_csv(f"{base_path}_faces.csv", index=False)
                
                messagebox.showinfo("Sucesso", f"Dados exportados:\n{base_path}_sessions.csv\n{base_path}_faces.csv")
                
            except Exception as e:
                messagebox.showerror("Erro", f"Erro ao exportar dados:\n{e}")
    
    def clear_database(self):
        """Limpa dados do banco de dados"""
        if messagebox.askyesno("Confirmar", "Limpar todos os dados do banco de dados?"):
            try:
                conn = sqlite3.connect(self.config.database_path)
                conn.execute("DELETE FROM tracking_sessions")
                conn.execute("DELETE FROM face_identifications")
                conn.commit()
                conn.close()
                
                messagebox.showinfo("Sucesso", "Banco de dados limpo!")
                
            except Exception as e:
                messagebox.showerror("Erro", f"Erro ao limpar banco:\n{e}")
    
    def calibrate_camera(self):
        """Abre utilit√°rio de calibra√ß√£o da c√¢mera"""
        messagebox.showinfo("Calibra√ß√£o", "Funcionalidade de calibra√ß√£o ser√° implementada em vers√£o futura")
    
    def show_about(self):
        """Mostra informa√ß√µes sobre o sistema"""
        about_text = """
üõ∞Ô∏è ESP32-CAM AI Tracking System Pro
Vers√£o 2.0

Sistema avan√ßado de rastreamento com:
‚Ä¢ YOLO v8 para detec√ß√£o de pessoas
‚Ä¢ DeepSORT para tracking robusto  
‚Ä¢ Reconhecimento facial com dlib
‚Ä¢ Interface moderna e intuitiva
‚Ä¢ Banco de dados SQLite
‚Ä¢ Estat√≠sticas em tempo real
‚Ä¢ Exporta√ß√£o de dados

Desenvolvido com tecnologias de ponta em AI/ML
        """
        messagebox.showinfo("Sobre", about_text.strip())
    
    def show_manual(self):
        """Mostra manual do usu√°rio"""
        manual_window = tk.Toplevel(self.root)
        manual_window.title("üìñ Manual do Usu√°rio")
        manual_window.geometry("700x600")
        manual_window.configure(bg='#2b2b2b')
        
        manual_text = tk.Text(
            manual_window, wrap=tk.WORD,
            bg='#3b3b3b', fg='white', font=('Arial', 11),
            padx=20, pady=20
        )
        manual_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        manual_content = """
üìñ MANUAL DO USU√ÅRIO - ESP32-CAM AI TRACKING SYSTEM PRO

üöÄ COMO USAR:

1. CONFIGURA√á√ÉO INICIAL
   ‚Ä¢ Configure a URL da ESP32-CAM no campo correspondente
   ‚Ä¢ Ajuste o threshold de detec√ß√£o (0.1 a 0.9)
   ‚Ä¢ Adicione faces conhecidas pelo menu "Gerenciar Faces"

2. INICIANDO O TRACKING
   ‚Ä¢ Clique em "‚ñ∂Ô∏è Iniciar" para come√ßar
   ‚Ä¢ Use "‚è∏Ô∏è Pausar" para pausar temporariamente
   ‚Ä¢ Use "‚èπÔ∏è Parar" para finalizar completamente

3. SALVANDO FRAMES
   ‚Ä¢ Clique em "üíæ Salvar" para capturar o frame atual
   ‚Ä¢ Os frames s√£o salvos na pasta "tracking_outputs"

4. GERENCIAMENTO DE FACES
   ‚Ä¢ Menu "Ferramentas" ‚Üí "Gerenciar Faces"
   ‚Ä¢ Adicione fotos das pessoas conhecidas
   ‚Ä¢ O sistema reconhecer√° automaticamente

5. ESTAT√çSTICAS
   ‚Ä¢ Clique em "üìä Estat√≠sticas" para ver gr√°ficos detalhados
   ‚Ä¢ Dados s√£o salvos automaticamente no banco SQLite

6. EXPORTA√á√ÉO DE DADOS
   ‚Ä¢ Menu "Arquivo" ‚Üí "Exportar Dados"
   ‚Ä¢ Gera arquivos CSV com todas as detec√ß√µes

üîß CONFIGURA√á√ïES AVAN√áADAS:

‚Ä¢ URLs de Backup: O sistema tenta m√∫ltiplas URLs automaticamente
‚Ä¢ Banco de Dados: SQLite local para persist√™ncia
‚Ä¢ Performance: Ajuste autom√°tico baseado na capacidade do sistema

‚ö†Ô∏è TROUBLESHOOTING:

‚Ä¢ Conex√£o ESP32: Use "Ferramentas" ‚Üí "Testar Conex√£o"
‚Ä¢ Performance baixa: Reduza resolu√ß√£o ou aumente frame skip
‚Ä¢ Reconhecimento facial: Certifique-se que face_recognition est√° instalado

üìû SUPORTE:
Sistema desenvolvido com tecnologias de ponta em AI/ML
        """
        
        manual_text.insert(1.0, manual_content.strip())
        manual_text.config(state='disabled')  # Somente leitura
        
        # Scrollbar para o manual
        scrollbar_manual = tk.Scrollbar(manual_window)
        scrollbar_manual.pack(side=tk.RIGHT, fill=tk.Y)
        manual_text.config(yscrollcommand=scrollbar_manual.set)
        scrollbar_manual.config(command=manual_text.yview)
    
    def on_closing(self):
        """Callback para fechamento da aplica√ß√£o"""
        if self.is_running:
            if messagebox.askyesno("Fechar", "Sistema em execu√ß√£o. Deseja realmente sair?"):
                self.stop_tracking()
                self.root.after(1000, self.root.destroy)  # Aguardar 1s para finalizar threads
        else:
            self.root.destroy()
    
    def run(self):
        """Inicia a aplica√ß√£o"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        logger.info("üñ•Ô∏è Interface gr√°fica iniciada")
        self.root.mainloop()

def main():
    """Fun√ß√£o principal do sistema"""
    try:
        # Configura√ß√£o do sistema
        config = SystemConfig(
            ESP32_STREAM_URL="http://192.168.0.100:81/stream",
            esp32_url="http://192.168.0.100:81/stream",
            backup_urls=[
                "http://192.168.1.100:81/stream",
                "http://192.168.0.101:81/stream"
            ],
            yolo_model="yolov8n.pt",
            detection_threshold=0.5,
            display_width=800,
            display_height=600,
            fps_limit=30
        )
        
        logger.info("üöÄ Iniciando ESP32-CAM AI Tracking System Pro")
        logger.info(f"Configura√ß√£o: {config}")
        
        # Criar e executar aplica√ß√£o
        app = AdvancedTrackingGUI(config)
        app.run()
        
    except KeyboardInterrupt:
        logger.info("Sistema interrompido pelo usu√°rio")
    except Exception as e:
        logger.error(f"Erro cr√≠tico no sistema: {e}")
        messagebox.showerror("Erro Cr√≠tico", f"Erro no sistema:\n{e}")
    finally:
        logger.info("Sistema finalizado")

if __name__ == "__main__":
    main()
